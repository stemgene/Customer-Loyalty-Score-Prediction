{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/preprocess/train.csv')\n",
    "test = pd.read_csv('./dataset/preprocess/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 1742)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>authorized_flag&amp;1&amp;purchase_amount</th>\n",
       "      <th>authorized_flag&amp;1&amp;installments</th>\n",
       "      <th>city_id&amp;19&amp;purchase_amount</th>\n",
       "      <th>city_id&amp;19&amp;installments</th>\n",
       "      <th>...</th>\n",
       "      <th>category_4_var</th>\n",
       "      <th>category_4_skew</th>\n",
       "      <th>category_4_sum</th>\n",
       "      <th>city_id_nunique</th>\n",
       "      <th>merchant_category_id_nunique</th>\n",
       "      <th>merchant_id_nunique</th>\n",
       "      <th>state_id_nunique</th>\n",
       "      <th>subsector_id_nunique</th>\n",
       "      <th>card_id_size</th>\n",
       "      <th>card_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>-170.641218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.422815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054623</td>\n",
       "      <td>-3.811953</td>\n",
       "      <td>261.0</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>-213.239185</td>\n",
       "      <td>507.0</td>\n",
       "      <td>-4.782308</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075036</td>\n",
       "      <td>-3.073118</td>\n",
       "      <td>327.0</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>-28.528749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.705405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065011</td>\n",
       "      <td>-3.548480</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>-54.145736</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-0.707839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>-6.361110</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>-88.966702</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091496</td>\n",
       "      <td>-2.668681</td>\n",
       "      <td>151.0</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>103</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0                  67  C_ID_92a2005557          5          2          1   \n",
       "1                  62  C_ID_3d0044924f          4          1          0   \n",
       "2                  57  C_ID_d639edf6cd          2          2          0   \n",
       "3                  70  C_ID_186d6a6901          4          3          0   \n",
       "4                  72  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  authorized_flag&1&purchase_amount  \\\n",
       "0 -0.820283                        -170.641218   \n",
       "1  0.392913                        -213.239185   \n",
       "2  0.688056                         -28.528749   \n",
       "3  0.142495                         -54.145736   \n",
       "4 -0.159749                         -88.966702   \n",
       "\n",
       "   authorized_flag&1&installments  city_id&19&purchase_amount  \\\n",
       "0                             0.0                   -1.422815   \n",
       "1                           507.0                   -4.782308   \n",
       "2                             0.0                   -0.705405   \n",
       "3                            89.0                   -0.707839   \n",
       "4                           179.0                    0.000000   \n",
       "\n",
       "   city_id&19&installments  ...  category_4_var  category_4_skew  \\\n",
       "0                      0.0  ...        0.054623        -3.811953   \n",
       "1                      7.0  ...        0.075036        -3.073118   \n",
       "2                      0.0  ...        0.065011        -3.548480   \n",
       "3                      1.0  ...        0.023523        -6.361110   \n",
       "4                      0.0  ...        0.091496        -2.668681   \n",
       "\n",
       "   category_4_sum  city_id_nunique  merchant_category_id_nunique  \\\n",
       "0           261.0                9                            46   \n",
       "1           327.0                9                            58   \n",
       "2            41.0                5                             9   \n",
       "3            82.0                7                            28   \n",
       "4           151.0                7                            37   \n",
       "\n",
       "   merchant_id_nunique  state_id_nunique  subsector_id_nunique  card_id_size  \\\n",
       "0                  118                 3                    21           283   \n",
       "1                  148                 3                    24           356   \n",
       "2                   14                 2                     8            44   \n",
       "3                   57                 5                    15            84   \n",
       "4                  103                 7                    19           169   \n",
       "\n",
       "   card_id_count  \n",
       "0            283  \n",
       "1            356  \n",
       "2             44  \n",
       "3             84  \n",
       "4            169  \n",
       "\n",
       "[5 rows x 1742 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22607061885876684"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train) / train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.columns.tolist()\n",
    "features.remove('card_id')\n",
    "features.remove('target')\n",
    "featureSelect = features[:]\n",
    "\n",
    "corr = []\n",
    "for fea in featureSelect:\n",
    "    corr.append(abs(train[[fea, 'target']].fillna(0).corr().values[0][1]))\n",
    "\n",
    "se = pd.Series(corr, index=featureSelect).sort_values(ascending=False)\n",
    "feature_select = ['card_id'] + se[:300].index.tolist()\n",
    "\n",
    "train_RF = train[feature_select + ['target']]\n",
    "test_RF = test[feature_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 302)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_RF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 301)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_RF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select_pearson(train, test):\n",
    "    \"\"\"\n",
    "    Feature selection based on the pearson coefficient\n",
    "    :param train:  training set\n",
    "    :param test: test set\n",
    "    :return: training and test sets after selection\n",
    "    \"\"\"\n",
    "    print('feature_select...')\n",
    "    features = train.columns.tolist()\n",
    "    features.remove(\"card_id\")\n",
    "    features.remove(\"target\")\n",
    "    featureSelect = features[:]\n",
    "\n",
    "    # 去掉缺失值比例超过0.99的\n",
    "    for fea in features:\n",
    "        if train[fea].isnull().sum() / train.shape[0] >= 0.99:\n",
    "            featureSelect.remove(fea)\n",
    "\n",
    "    # 进行pearson相关性计算\n",
    "    corr = []\n",
    "    for fea in featureSelect:\n",
    "        corr.append(abs(train[[fea, 'target']].fillna(0).corr().values[0][1]))\n",
    "\n",
    "    # 取top300的特征进行建模，具体数量可选\n",
    "    se = pd.Series(corr, index=featureSelect).sort_values(ascending=False)\n",
    "    feature_select = ['card_id'] + se[:300].index.tolist()\n",
    "    print('done')\n",
    "    return train[feature_select + ['target']], test[feature_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grid_search(train):\n",
    "    \"\"\"\n",
    "    网格搜索参数调优\n",
    "    :param train:训练集\n",
    "    :return:网格搜索训练结果\n",
    "    \"\"\"\n",
    "\n",
    "    print('param_grid_search')\n",
    "    features = train.columns.tolist()\n",
    "    features.remove(\"card_id\")\n",
    "    features.remove(\"target\")\n",
    "    parameter_space = {\n",
    "        \"n_estimators\": [81], \n",
    "        \"min_samples_leaf\": [31],\n",
    "        \"min_samples_split\": [2],\n",
    "        \"max_depth\": [10],\n",
    "        \"max_features\": [80]\n",
    "    }\n",
    "    \n",
    "\n",
    "    print(\"Tuning hyper-parameters for mse\")\n",
    "\n",
    "    clf = RandomForestRegressor(\n",
    "        criterion=\"squared_error\",\n",
    "        n_jobs=15,\n",
    "        random_state=22)\n",
    "\n",
    "    grid = GridSearchCV(clf, parameter_space, cv=2, scoring=\"neg_mean_squared_error\")\n",
    "    grid.fit(train[features].values, train['target'].values)\n",
    "    \n",
    "\n",
    "    print(\"best_params_:\")\n",
    "    print(grid.best_params_)\n",
    "    means = grid.cv_results_[\"mean_test_score\"]\n",
    "    stds = grid.cv_results_[\"std_test_score\"]\n",
    "    # 此处额外考虑观察交叉验证过程中不同超参数的\n",
    "    for mean, std, params in zip(means, stds, grid.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_grid_search\n",
      "Tuning hyper-parameters for mse\n",
      "best_params_:\n",
      "{'max_depth': 10, 'max_features': 80, 'min_samples_leaf': 31, 'min_samples_split': 2, 'n_estimators': 81}\n",
      "-13.617 (+/-0.088) for {'max_depth': 10, 'max_features': 80, 'min_samples_leaf': 31, 'min_samples_split': 2, 'n_estimators': 81}\n"
     ]
    }
   ],
   "source": [
    "grid = param_grid_search(train_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.690154811274698"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(train, test, best_clf):\n",
    "    \"\"\"\n",
    "    To train and predict\n",
    "    :param train: training set\n",
    "    :param test: test set\n",
    "    :param best_clf: the best classifier\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # step 1: feature selection\n",
    "    print('train_predict...')\n",
    "    features = train.columns.tolist()\n",
    "    features.remove(\"card_id\")\n",
    "    features.remove(\"target\")\n",
    "\n",
    "    # step 2: Cross Validation\n",
    "    prediction_test = 0\n",
    "    cv_score = []\n",
    "    prediction_train = pd.Series()\n",
    "\n",
    "    kf = KFold(n_splits=5, random_state=22, shuffle=True)\n",
    "    for train_part_index, eval_index in kf.split(train[features], train['target']):\n",
    "        # train the model on training set\n",
    "        best_clf.fit(train[features].loc[train_part_index].values, train['target'].loc[train_part_index].values)\n",
    "        # Add the prediction result\n",
    "        prediction_test += best_clf.predict(test[features].values)\n",
    "        # prediction on validation test\n",
    "        eval_pre = best_clf.predict(train[features].loc[eval_index].values)\n",
    "        # evaluate on validation prediction with MSE\n",
    "        score = np.sqrt(mean_squared_error(train['target'].loc[eval_index].values, eval_pre))\n",
    "        # Put MSE score into cv_score list\n",
    "        cv_score.append(score)\n",
    "        print(score)\n",
    "        # Put prediction on validation set into prediction_train\n",
    "        prediction_train = prediction_train.append(pd.Series(best_clf.predict(train[features].loc[eval_index]), index=eval_index))\n",
    "    \n",
    "    print(cv_score, sum(cv_score)/5)\n",
    "    pd.Series(prediction_train.sort_index().values).to_csv(\"./dataset/preprocess/train_randomforest.csv\", index=False)\n",
    "    pd.Series(prediction_test / 5).to_csv(\"./dataset/preprocess/test_randomforest.csv\", index=False)\n",
    "    # Append the label 'target' to the test set\n",
    "    test['target'] = prediction_test / 5\n",
    "    test[['card_id', 'target']].to_csv(\"result/submission_randomforest_5kf.csv\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_3428\\1683043823.py:19: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  prediction_train = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.675458048156077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_3428\\1683043823.py:35: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(best_clf.predict(train[features].loc[eval_index]), index=eval_index))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7098960303168167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_3428\\1683043823.py:35: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(best_clf.predict(train[features].loc[eval_index]), index=eval_index))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7175960057854875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_3428\\1683043823.py:35: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(best_clf.predict(train[features].loc[eval_index]), index=eval_index))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.682888749975916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_3428\\1683043823.py:35: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(best_clf.predict(train[features].loc[eval_index]), index=eval_index))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.646825949050688\n",
      "[3.675458048156077, 3.7098960303168167, 3.7175960057854875, 3.682888749975916, 3.646825949050688] 3.686532956656997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_3428\\1683043823.py:35: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(best_clf.predict(train[features].loc[eval_index]), index=eval_index))\n",
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_3428\\1683043823.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['target'] = prediction_test / 5\n"
     ]
    }
   ],
   "source": [
    "train_predict(train_RF, test_RF, grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
