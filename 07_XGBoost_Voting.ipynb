{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1588ccc8-a6be-4d81-b189-f8a01f2b1707",
   "metadata": {},
   "source": [
    "# NLP特征优化+XGBoost建模+贝叶斯优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdbb57-d637-41dd-99a7-e72702c8495c",
   "metadata": {},
   "source": [
    "## 1.NLP Feature Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584cc08",
   "metadata": {},
   "source": [
    "I found there were many columns related to ID, such as `merchant_id`, `merchant_category_id`, `state_id`, `subsector_id`, `city_id`, these values inflect customer's behavior. For example, for a customer A, if a certain merchant id happens a lot in his transaction record, it means A likes this merchant. Furthermore, if this merchant record in many customers', it means this merchant is popular, and it also means customer A is similar to other customers, if not, A has a special like. \n",
    "\n",
    "In order to mining this information, I will apply CountVector and TF-IDF. Specificly, CountVector can extract merchant information of a customer, and TF-IDF can extract if many customers like one product at the same time.\n",
    "\n",
    "If we apply NLP approaches, there is an issue we should consider which is there are too many new features and most of them are sparse. So I'll introduce associated method `sparse` from `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "15058d4a-d8b8-4e9f-95c0-9468907680f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22354969-2d16-4d66-be86-1e8c4ad868fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, these are the original dataset\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test =  pd.read_csv('data/test.csv')\n",
    "merchant = pd.read_csv('data/merchants.csv')\n",
    "new_transaction = pd.read_csv('data/new_merchant_transactions.csv')\n",
    "history_transaction = pd.read_csv('data/historical_transactions.csv')\n",
    "transaction = pd.concat([new_transaction, history_transaction], axis=0, ignore_index=True)\n",
    "del new_transaction\n",
    "del history_transaction\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5993a615-34b3-4f7d-8b98-472f67be4340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id\n",
      "merchant_category_id\n",
      "state_id\n",
      "subsector_id\n",
      "city_id\n"
     ]
    }
   ],
   "source": [
    "nlp_features = ['merchant_id', 'merchant_category_id', 'state_id', 'subsector_id', 'city_id']\n",
    "\n",
    "for co in nlp_features:\n",
    "    print(co)\n",
    "    transaction[co] = transaction[co].astype(str)\n",
    "    temp = transaction[transaction['month_lag']>=0].groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_new']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id')\n",
    "    test = pd.merge(test, temp, how='left', on='card_id')\n",
    "\n",
    "    temp = transaction[transaction['month_lag']<0].groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_hist']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id')\n",
    "    test = pd.merge(test, temp, how='left', on='card_id')\n",
    "\n",
    "    temp = transaction.groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_all']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id').fillna(\"-1\")\n",
    "    test = pd.merge(test, temp, how='left', on='card_id').fillna(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbcc614-3fbd-4d24-8c59-a271c2a382b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id_new\n",
      "merchant_id_hist\n",
      "merchant_id_all\n",
      "merchant_category_id_new\n",
      "merchant_category_id_hist\n",
      "merchant_category_id_all\n",
      "state_id_new\n",
      "state_id_hist\n",
      "state_id_all\n",
      "subsector_id_new\n",
      "subsector_id_hist\n",
      "subsector_id_all\n",
      "city_id_new\n",
      "city_id_hist\n",
      "city_id_all\n"
     ]
    }
   ],
   "source": [
    "# 创建空DataFrame用于保存NLP特征\n",
    "train_x = pd.DataFrame()\n",
    "test_x = pd.DataFrame()\n",
    "\n",
    "# 实例化CountVectorizer评估器与TfidfVectorizer评估器\n",
    "cntv = CountVectorizer()\n",
    "tfv = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "\n",
    "# 创建空列表用户保存修正后的列名称\n",
    "vector_feature =[]\n",
    "for co in ['merchant_id', 'merchant_category_id', 'state_id', 'subsector_id', 'city_id']:\n",
    "    vector_feature.extend([co+'_new', co+'_hist', co+'_all'])\n",
    "    \n",
    "# 提取每一列进行新特征衍生\n",
    "for feature in vector_feature:\n",
    "    print(feature)\n",
    "    cntv.fit([feature].append(test[feature]))\n",
    "    train_x = sparse.hstack((train_x, cntv.transform(train[feature]))).tocsr()\n",
    "    test_x = sparse.hstack((test_x, cntv.transform(test[feature]))).tocsr()\n",
    "    \n",
    "    tfv.fit(train[feature].append(test[feature]))\n",
    "    train_x = sparse.hstack((train_x, tfv.transform(train[feature]))).tocsr()\n",
    "    test_x = sparse.hstack((test_x, tfv.transform(test[feature]))).tocsr()\n",
    "    \n",
    "# 保存NLP特征衍生结果\n",
    "sparse.save_npz(\"preprocess/train_nlp.npz\", train_x)\n",
    "sparse.save_npz(\"preprocess/test_nlp.npz\", test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22752d7-b5cb-411f-a0c8-64f2c1c041f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 1846286)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d7984-bb60-4e40-8af6-f19fed4b923b",
   "metadata": {},
   "source": [
    "## 2.XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fbaf209-2a63-40a0-8863-5cf106117294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import f_regression\n",
    "from numpy.random import RandomState\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e43f799e-d011-42ec-b9bc-c99a083a9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('preprocess/train.csv')\n",
    "test = pd.read_csv('preprocess/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cbc35a4-6d7c-48d6-abc9-4b6e06c955bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.columns.tolist()\n",
    "features.remove('card_id')\n",
    "features.remove('target')\n",
    "\n",
    "train_x = sparse.load_npz(\"preprocess/train_nlp.npz\")\n",
    "test_x = sparse.load_npz(\"preprocess/test_nlp.npz\")\n",
    "\n",
    "train_x = sparse.hstack((train_x, train[features])).tocsr()\n",
    "test_x = sparse.hstack((test_x, test[features])).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c97de2-bffa-4e26-bbb8-c77c8f2dcb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数回调函数\n",
    "def params_append(params):\n",
    "    \"\"\"\n",
    "\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    params['objective'] = 'reg:squarederror'\n",
    "    params['eval_metric'] = 'rmse'\n",
    "    params[\"min_child_weight\"] = int(params[\"min_child_weight\"])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    return params\n",
    "\n",
    "# 模型优化函数\n",
    "def param_beyesian(train):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Part 1.数据准备\n",
    "    train_y = pd.read_csv(\"data/train.csv\")['target']\n",
    "    # 数据封装\n",
    "    sample_index = train_y.sample(frac=0.1, random_state=2020).index.tolist()\n",
    "    train_data = xgb.DMatrix(train.tocsr()[sample_index, :\n",
    "                             ], train_y.loc[sample_index].values, silent=True)\n",
    "    \n",
    "    # 借助cv过程构建目标函数\n",
    "    def xgb_cv(colsample_bytree, subsample, min_child_weight, max_depth,\n",
    "               reg_alpha, eta,\n",
    "               reg_lambda):\n",
    "        \"\"\"\n",
    "\n",
    "        :param colsample_bytree:\n",
    "        :param subsample:\n",
    "        :param min_child_weight:\n",
    "        :param max_depth:\n",
    "        :param reg_alpha:\n",
    "        :param eta:\n",
    "        :param reg_lambda:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        params = {'objective': 'reg:squarederror',\n",
    "                  'early_stopping_round': 50,\n",
    "                  'eval_metric': 'rmse'}\n",
    "        params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "        params['subsample'] = max(min(subsample, 1), 0)\n",
    "        params[\"min_child_weight\"] = int(min_child_weight)\n",
    "        params['max_depth'] = int(max_depth)\n",
    "        params['eta'] = float(eta)\n",
    "        params['reg_alpha'] = max(reg_alpha, 0)\n",
    "        params['reg_lambda'] = max(reg_lambda, 0)\n",
    "        print(params)\n",
    "        cv_result = xgb.cv(params, train_data,\n",
    "                           num_boost_round=1000,\n",
    "                           nfold=2, seed=2,\n",
    "                           stratified=False,\n",
    "                           shuffle=True,\n",
    "                           early_stopping_rounds=30,\n",
    "                           verbose_eval=False)\n",
    "        return -min(cv_result['test-rmse-mean'])\n",
    "    \n",
    "    # 调用贝叶斯优化器进行模型优化\n",
    "    xgb_bo = BayesianOptimization(\n",
    "        xgb_cv,\n",
    "        {'colsample_bytree': (0.5, 1),\n",
    "         'subsample': (0.5, 1),\n",
    "         'min_child_weight': (1, 30),\n",
    "         'max_depth': (5, 12),\n",
    "         'reg_alpha': (0, 5),\n",
    "         'eta':(0.02, 0.2),\n",
    "         'reg_lambda': (0, 5)}\n",
    "    )\n",
    "    xgb_bo.maximize(init_points=21, n_iter=5)  # init_points表示初始点，n_iter代表迭代次数（即采样数）\n",
    "    print(xgb_bo.max['target'], xgb_bo.max['params'])\n",
    "    return xgb_bo.max['params']\n",
    "\n",
    "# 交叉验证预测函数\n",
    "def train_predict(train, test, params):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train:\n",
    "    :param test:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_y = pd.read_csv(\"data/train.csv\")['target']\n",
    "    test_data = xgb.DMatrix(test)\n",
    "\n",
    "    params = params_append(params)\n",
    "    kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    prediction_test = 0\n",
    "    cv_score = []\n",
    "    prediction_train = pd.Series()\n",
    "    ESR = 30\n",
    "    NBR = 10000\n",
    "    VBE = 50\n",
    "    for train_part_index, eval_index in kf.split(train, train_y):\n",
    "        # 模型训练\n",
    "        train_part = xgb.DMatrix(train.tocsr()[train_part_index, :],\n",
    "                                 train_y.loc[train_part_index])\n",
    "        eval = xgb.DMatrix(train.tocsr()[eval_index, :],\n",
    "                           train_y.loc[eval_index])\n",
    "        bst = xgb.train(params, train_part, NBR, [(train_part, 'train'),\n",
    "                                                          (eval, 'eval')], verbose_eval=VBE,\n",
    "                        maximize=False, early_stopping_rounds=ESR, )\n",
    "        prediction_test += bst.predict(test_data)\n",
    "        eval_pre = bst.predict(eval)\n",
    "        prediction_train = prediction_train.append(pd.Series(eval_pre, index=eval_index))\n",
    "        score = np.sqrt(mean_squared_error(train_y.loc[eval_index].values, eval_pre))\n",
    "        cv_score.append(score)\n",
    "    print(cv_score, sum(cv_score) / 5)\n",
    "    pd.Series(prediction_train.sort_index().values).to_csv(\"preprocess/train_xgboost.csv\", index=False)\n",
    "    pd.Series(prediction_test / 5).to_csv(\"preprocess/test_xgboost.csv\", index=False)\n",
    "    test = pd.read_csv('data/test.csv')\n",
    "    test['target'] = prediction_test / 5\n",
    "    test[['card_id', 'target']].to_csv(\"result/submission_xgboost.csv\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1add86ca-6169-4932-888d-9204bc962657",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |    eta    | max_depth | min_ch... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.9008280232486963, 'subsample': 0.8904106813206965, 'min_child_weight': 29, 'max_depth': 9, 'eta': 0.15949688000040066, 'reg_alpha': 1.8850960576404892, 'reg_lambda': 4.436160789463865}\n",
      "[12:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.828   \u001b[0m | \u001b[0m 0.9008  \u001b[0m | \u001b[0m 0.1595  \u001b[0m | \u001b[0m 9.636   \u001b[0m | \u001b[0m 29.93   \u001b[0m | \u001b[0m 1.885   \u001b[0m | \u001b[0m 4.436   \u001b[0m | \u001b[0m 0.8904  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.8733613720817149, 'subsample': 0.6142495949337223, 'min_child_weight': 29, 'max_depth': 8, 'eta': 0.1802456543940385, 'reg_alpha': 0.8072782146576124, 'reg_lambda': 2.284382168716956}\n",
      "[12:54:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:54:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-3.861   \u001b[0m | \u001b[0m 0.8734  \u001b[0m | \u001b[0m 0.1802  \u001b[0m | \u001b[0m 8.376   \u001b[0m | \u001b[0m 29.33   \u001b[0m | \u001b[0m 0.8073  \u001b[0m | \u001b[0m 2.284   \u001b[0m | \u001b[0m 0.6142  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.9268730478860339, 'subsample': 0.9187182128076231, 'min_child_weight': 18, 'max_depth': 10, 'eta': 0.10485164882690341, 'reg_alpha': 1.4052740152170013, 'reg_lambda': 4.420615175732838}\n",
      "[12:55:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:55:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-3.848   \u001b[0m | \u001b[0m 0.9269  \u001b[0m | \u001b[0m 0.1049  \u001b[0m | \u001b[0m 10.6    \u001b[0m | \u001b[0m 18.53   \u001b[0m | \u001b[0m 1.405   \u001b[0m | \u001b[0m 4.421   \u001b[0m | \u001b[0m 0.9187  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.625422443194849, 'subsample': 0.6710318901133161, 'min_child_weight': 27, 'max_depth': 8, 'eta': 0.05185743596319062, 'reg_alpha': 1.1690459082772615, 'reg_lambda': 3.562136294750095}\n",
      "[12:56:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:56:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-3.829   \u001b[0m | \u001b[0m 0.6254  \u001b[0m | \u001b[0m 0.05186 \u001b[0m | \u001b[0m 8.038   \u001b[0m | \u001b[0m 27.47   \u001b[0m | \u001b[0m 1.169   \u001b[0m | \u001b[0m 3.562   \u001b[0m | \u001b[0m 0.671   \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.902497211065604, 'subsample': 0.8413464797085647, 'min_child_weight': 27, 'max_depth': 8, 'eta': 0.09748251874712145, 'reg_alpha': 2.9238818257239756, 'reg_lambda': 0.6901256237971481}\n",
      "[12:58:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:58:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-3.824   \u001b[0m | \u001b[95m 0.9025  \u001b[0m | \u001b[95m 0.09748 \u001b[0m | \u001b[95m 8.835   \u001b[0m | \u001b[95m 27.77   \u001b[0m | \u001b[95m 2.924   \u001b[0m | \u001b[95m 0.6901  \u001b[0m | \u001b[95m 0.8413  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.9977024155365132, 'subsample': 0.8115473489069764, 'min_child_weight': 29, 'max_depth': 8, 'eta': 0.08573985701358497, 'reg_alpha': 4.39911724928385, 'reg_lambda': 0.98249230645374}\n",
      "[12:59:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:59:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-3.827   \u001b[0m | \u001b[0m 0.9977  \u001b[0m | \u001b[0m 0.08574 \u001b[0m | \u001b[0m 8.21    \u001b[0m | \u001b[0m 29.41   \u001b[0m | \u001b[0m 4.399   \u001b[0m | \u001b[0m 0.9825  \u001b[0m | \u001b[0m 0.8115  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.9407066205905263, 'subsample': 0.827880546540135, 'min_child_weight': 6, 'max_depth': 9, 'eta': 0.1061485706403698, 'reg_alpha': 2.139211485717212, 'reg_lambda': 3.2008526648164737}\n",
      "[13:00:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:00:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.851   \u001b[0m | \u001b[0m 0.9407  \u001b[0m | \u001b[0m 0.1061  \u001b[0m | \u001b[0m 9.67    \u001b[0m | \u001b[0m 6.107   \u001b[0m | \u001b[0m 2.139   \u001b[0m | \u001b[0m 3.201   \u001b[0m | \u001b[0m 0.8279  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.6566786860590916, 'subsample': 0.6452363126120251, 'min_child_weight': 18, 'max_depth': 8, 'eta': 0.14417434852557892, 'reg_alpha': 4.3160287883092066, 'reg_lambda': 3.5328339088472847}\n",
      "[13:02:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-3.848   \u001b[0m | \u001b[0m 0.6567  \u001b[0m | \u001b[0m 0.1442  \u001b[0m | \u001b[0m 8.496   \u001b[0m | \u001b[0m 18.79   \u001b[0m | \u001b[0m 4.316   \u001b[0m | \u001b[0m 3.533   \u001b[0m | \u001b[0m 0.6452  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.611191859916479, 'subsample': 0.9607934404730234, 'min_child_weight': 10, 'max_depth': 5, 'eta': 0.16887507984941832, 'reg_alpha': 1.8949997250691952, 'reg_lambda': 1.9700264363894808}\n",
      "[13:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-3.84    \u001b[0m | \u001b[0m 0.6112  \u001b[0m | \u001b[0m 0.1689  \u001b[0m | \u001b[0m 5.955   \u001b[0m | \u001b[0m 10.8    \u001b[0m | \u001b[0m 1.895   \u001b[0m | \u001b[0m 1.97    \u001b[0m | \u001b[0m 0.9608  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.5688557898775366, 'subsample': 0.792738671048387, 'min_child_weight': 8, 'max_depth': 8, 'eta': 0.029707284678996262, 'reg_alpha': 2.13929302944516, 'reg_lambda': 1.716127401031825}\n",
      "[13:03:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:03:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-3.833   \u001b[0m | \u001b[0m 0.5689  \u001b[0m | \u001b[0m 0.02971 \u001b[0m | \u001b[0m 8.436   \u001b[0m | \u001b[0m 8.559   \u001b[0m | \u001b[0m 2.139   \u001b[0m | \u001b[0m 1.716   \u001b[0m | \u001b[0m 0.7927  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.8909115661247835, 'subsample': 0.838354468762074, 'min_child_weight': 24, 'max_depth': 6, 'eta': 0.11054484780152028, 'reg_alpha': 4.1364437329554455, 'reg_lambda': 3.1715376094875305}\n",
      "[13:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-3.821   \u001b[0m | \u001b[95m 0.8909  \u001b[0m | \u001b[95m 0.1105  \u001b[0m | \u001b[95m 6.204   \u001b[0m | \u001b[95m 24.25   \u001b[0m | \u001b[95m 4.136   \u001b[0m | \u001b[95m 3.172   \u001b[0m | \u001b[95m 0.8384  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.9465569893212517, 'subsample': 0.5866450532823893, 'min_child_weight': 13, 'max_depth': 7, 'eta': 0.1596273004501417, 'reg_alpha': 2.364218860201553, 'reg_lambda': 1.7722559715723234}\n",
      "[13:06:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:06:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-3.881   \u001b[0m | \u001b[0m 0.9466  \u001b[0m | \u001b[0m 0.1596  \u001b[0m | \u001b[0m 7.621   \u001b[0m | \u001b[0m 13.79   \u001b[0m | \u001b[0m 2.364   \u001b[0m | \u001b[0m 1.772   \u001b[0m | \u001b[0m 0.5866  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.9627435399195992, 'subsample': 0.9808950735528328, 'min_child_weight': 27, 'max_depth': 6, 'eta': 0.05741987032403584, 'reg_alpha': 3.9968620363457683, 'reg_lambda': 0.4830516515499872}\n",
      "[13:07:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:07:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-3.812   \u001b[0m | \u001b[95m 0.9627  \u001b[0m | \u001b[95m 0.05742 \u001b[0m | \u001b[95m 6.407   \u001b[0m | \u001b[95m 27.35   \u001b[0m | \u001b[95m 3.997   \u001b[0m | \u001b[95m 0.4831  \u001b[0m | \u001b[95m 0.9809  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.9044844729820345, 'subsample': 0.5762009686960115, 'min_child_weight': 24, 'max_depth': 5, 'eta': 0.16975603999498512, 'reg_alpha': 3.085476522155029, 'reg_lambda': 3.5171910395636363}\n",
      "[13:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-3.838   \u001b[0m | \u001b[0m 0.9045  \u001b[0m | \u001b[0m 0.1698  \u001b[0m | \u001b[0m 5.856   \u001b[0m | \u001b[0m 24.39   \u001b[0m | \u001b[0m 3.085   \u001b[0m | \u001b[0m 3.517   \u001b[0m | \u001b[0m 0.5762  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.7325643867708108, 'subsample': 0.5099111689834741, 'min_child_weight': 2, 'max_depth': 6, 'eta': 0.1764589326251524, 'reg_alpha': 1.802265951008657, 'reg_lambda': 3.2543009145085158}\n",
      "[13:09:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.897   \u001b[0m | \u001b[0m 0.7326  \u001b[0m | \u001b[0m 0.1765  \u001b[0m | \u001b[0m 6.418   \u001b[0m | \u001b[0m 2.489   \u001b[0m | \u001b[0m 1.802   \u001b[0m | \u001b[0m 3.254   \u001b[0m | \u001b[0m 0.5099  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.6131120218876751, 'subsample': 0.5253206916632518, 'min_child_weight': 11, 'max_depth': 6, 'eta': 0.1719844380323167, 'reg_alpha': 2.357407785582822, 'reg_lambda': 3.375957679817562}\n",
      "[13:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:10:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-3.865   \u001b[0m | \u001b[0m 0.6131  \u001b[0m | \u001b[0m 0.172   \u001b[0m | \u001b[0m 6.231   \u001b[0m | \u001b[0m 11.49   \u001b[0m | \u001b[0m 2.357   \u001b[0m | \u001b[0m 3.376   \u001b[0m | \u001b[0m 0.5253  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.6831871509139502, 'subsample': 0.9297109754890269, 'min_child_weight': 2, 'max_depth': 10, 'eta': 0.04473277839394052, 'reg_alpha': 1.3430060896665403, 'reg_lambda': 3.918534812739465}\n",
      "[13:11:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:11:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-3.822   \u001b[0m | \u001b[0m 0.6832  \u001b[0m | \u001b[0m 0.04473 \u001b[0m | \u001b[0m 10.27   \u001b[0m | \u001b[0m 2.572   \u001b[0m | \u001b[0m 1.343   \u001b[0m | \u001b[0m 3.919   \u001b[0m | \u001b[0m 0.9297  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.523125333707535, 'subsample': 0.7392177712247874, 'min_child_weight': 8, 'max_depth': 5, 'eta': 0.139490251639574, 'reg_alpha': 0.14523540355518005, 'reg_lambda': 0.5513235601440791}\n",
      "[13:13:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-3.856   \u001b[0m | \u001b[0m 0.5231  \u001b[0m | \u001b[0m 0.1395  \u001b[0m | \u001b[0m 5.779   \u001b[0m | \u001b[0m 8.058   \u001b[0m | \u001b[0m 0.1452  \u001b[0m | \u001b[0m 0.5513  \u001b[0m | \u001b[0m 0.7392  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.7647893523603579, 'subsample': 0.9464736694936582, 'min_child_weight': 23, 'max_depth': 5, 'eta': 0.11531533678838223, 'reg_alpha': 4.517440315400995, 'reg_lambda': 0.063527226500667}\n",
      "[13:14:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:14:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-3.821   \u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 0.1153  \u001b[0m | \u001b[0m 5.54    \u001b[0m | \u001b[0m 23.44   \u001b[0m | \u001b[0m 4.517   \u001b[0m | \u001b[0m 0.06353 \u001b[0m | \u001b[0m 0.9465  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.7663684613824646, 'subsample': 0.681336879639247, 'min_child_weight': 29, 'max_depth': 11, 'eta': 0.0434838090691807, 'reg_alpha': 4.538172496852858, 'reg_lambda': 2.9134596476240175}\n",
      "[13:15:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:15:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-3.813   \u001b[0m | \u001b[0m 0.7664  \u001b[0m | \u001b[0m 0.04348 \u001b[0m | \u001b[0m 11.57   \u001b[0m | \u001b[0m 29.03   \u001b[0m | \u001b[0m 4.538   \u001b[0m | \u001b[0m 2.913   \u001b[0m | \u001b[0m 0.6813  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.8349846959575062, 'subsample': 0.9790484991878241, 'min_child_weight': 7, 'max_depth': 5, 'eta': 0.11336872232404879, 'reg_alpha': 0.027603113711953675, 'reg_lambda': 3.4360173002023804}\n",
      "[13:17:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:17:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-3.83    \u001b[0m | \u001b[0m 0.835   \u001b[0m | \u001b[0m 0.1134  \u001b[0m | \u001b[0m 5.967   \u001b[0m | \u001b[0m 7.343   \u001b[0m | \u001b[0m 0.0276  \u001b[0m | \u001b[0m 3.436   \u001b[0m | \u001b[0m 0.979   \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.8207939072435217, 'subsample': 1.0, 'min_child_weight': 25, 'max_depth': 7, 'eta': 0.045052085309867346, 'reg_alpha': 4.63105080372857, 'reg_lambda': 1.2866888587445227}\n",
      "[13:18:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:18:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-3.814   \u001b[0m | \u001b[0m 0.8208  \u001b[0m | \u001b[0m 0.04505 \u001b[0m | \u001b[0m 7.272   \u001b[0m | \u001b[0m 25.61   \u001b[0m | \u001b[0m 4.631   \u001b[0m | \u001b[0m 1.287   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.7415820237405875, 'subsample': 0.9875025924634507, 'min_child_weight': 27, 'max_depth': 9, 'eta': 0.02, 'reg_alpha': 4.575465304651051, 'reg_lambda': 3.3858651807679534}\n",
      "[13:21:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:21:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-3.817   \u001b[0m | \u001b[0m 0.7416  \u001b[0m | \u001b[0m 0.02    \u001b[0m | \u001b[0m 9.347   \u001b[0m | \u001b[0m 27.15   \u001b[0m | \u001b[0m 4.575   \u001b[0m | \u001b[0m 3.386   \u001b[0m | \u001b[0m 0.9875  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.5, 'subsample': 0.733927508291536, 'min_child_weight': 27, 'max_depth': 11, 'eta': 0.02, 'reg_alpha': 3.32497669686325, 'reg_lambda': 4.9571016974842514}\n",
      "[13:25:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:25:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 24      \u001b[0m | \u001b[95m-3.803   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.02    \u001b[0m | \u001b[95m 11.71   \u001b[0m | \u001b[95m 27.6    \u001b[0m | \u001b[95m 3.325   \u001b[0m | \u001b[95m 4.957   \u001b[0m | \u001b[95m 0.7339  \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 0.5, 'subsample': 0.5, 'min_child_weight': 26, 'max_depth': 12, 'eta': 0.02, 'reg_alpha': 3.081921668614422, 'reg_lambda': 3.0163834184284712}\n",
      "[13:27:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:27:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.813   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.02    \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 26.01   \u001b[0m | \u001b[0m 3.082   \u001b[0m | \u001b[0m 3.016   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'early_stopping_round': 50, 'eval_metric': 'rmse', 'colsample_bytree': 1.0, 'subsample': 1.0, 'min_child_weight': 25, 'max_depth': 12, 'eta': 0.2, 'reg_alpha': 5.0, 'reg_lambda': 5.0}\n",
      "[13:30:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:30:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-3.864   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 25.92   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=============================================================================================================\n",
      "-3.8032684999999997 {'colsample_bytree': 0.5, 'eta': 0.02, 'max_depth': 11.708480184158471, 'min_child_weight': 27.598200792362622, 'reg_alpha': 3.32497669686325, 'reg_lambda': 4.9571016974842514, 'subsample': 0.733927508291536}\n"
     ]
    }
   ],
   "source": [
    "best_clf = param_beyesian(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07424b25-6b20-4b20-84b9-9207d7884331",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-9e501afc8b2a>:87: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  prediction_train = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.93743\teval-rmse:3.94887\n",
      "[50]\ttrain-rmse:3.49914\teval-rmse:3.73093\n",
      "[100]\ttrain-rmse:3.32144\teval-rmse:3.68839\n",
      "[150]\ttrain-rmse:3.23772\teval-rmse:3.67804\n",
      "[200]\ttrain-rmse:3.20197\teval-rmse:3.67385\n",
      "[250]\ttrain-rmse:3.17762\teval-rmse:3.67253\n",
      "[300]\ttrain-rmse:3.15443\teval-rmse:3.67234\n",
      "[302]\ttrain-rmse:3.15403\teval-rmse:3.67244\n",
      "[0]\ttrain-rmse:3.94448\teval-rmse:3.92137\n",
      "[50]\ttrain-rmse:3.50756\teval-rmse:3.69474\n",
      "[100]\ttrain-rmse:3.32726\teval-rmse:3.64895\n",
      "[150]\ttrain-rmse:3.24642\teval-rmse:3.63666\n",
      "[200]\ttrain-rmse:3.20761\teval-rmse:3.63409\n",
      "[250]\ttrain-rmse:3.18269\teval-rmse:3.63341\n",
      "[300]\ttrain-rmse:3.15935\teval-rmse:3.63319\n",
      "[350]\ttrain-rmse:3.13936\teval-rmse:3.63291\n",
      "[354]\ttrain-rmse:3.13787\teval-rmse:3.63293\n",
      "[0]\ttrain-rmse:3.93301\teval-rmse:3.96766\n",
      "[50]\ttrain-rmse:3.48744\teval-rmse:3.75187\n",
      "[100]\ttrain-rmse:3.30316\teval-rmse:3.71049\n",
      "[150]\ttrain-rmse:3.21876\teval-rmse:3.70025\n",
      "[200]\ttrain-rmse:3.18515\teval-rmse:3.69695\n",
      "[250]\ttrain-rmse:3.16190\teval-rmse:3.69627\n",
      "[300]\ttrain-rmse:3.14040\teval-rmse:3.69544\n",
      "[321]\ttrain-rmse:3.13221\teval-rmse:3.69595\n",
      "[0]\ttrain-rmse:3.91287\teval-rmse:4.04674\n",
      "[50]\ttrain-rmse:3.47627\teval-rmse:3.82653\n",
      "[100]\ttrain-rmse:3.28783\teval-rmse:3.78026\n",
      "[150]\ttrain-rmse:3.20957\teval-rmse:3.76870\n",
      "[200]\ttrain-rmse:3.17786\teval-rmse:3.76575\n",
      "[250]\ttrain-rmse:3.15028\teval-rmse:3.76448\n",
      "[300]\ttrain-rmse:3.12888\teval-rmse:3.76443\n",
      "[314]\ttrain-rmse:3.12480\teval-rmse:3.76418\n",
      "[0]\ttrain-rmse:3.96661\teval-rmse:3.83160\n",
      "[50]\ttrain-rmse:3.52079\teval-rmse:3.61955\n",
      "[100]\ttrain-rmse:3.33833\teval-rmse:3.57930\n",
      "[150]\ttrain-rmse:3.26075\teval-rmse:3.56961\n",
      "[200]\ttrain-rmse:3.22778\teval-rmse:3.56733\n",
      "[250]\ttrain-rmse:3.19642\teval-rmse:3.56590\n",
      "[289]\ttrain-rmse:3.17949\teval-rmse:3.56588\n",
      "[3.6724352915788456, 3.632935489439316, 3.6959392218600025, 3.7641771493981997, 3.5658763997083103] 3.6662727103969344\n"
     ]
    }
   ],
   "source": [
    "train_predict(train_x, test_x, best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f69a3c-d282-42e0-9c3c-a4ab9d9dd892",
   "metadata": {},
   "source": [
    "| Model | RMSE | \n",
    "| ------ | ------ |\n",
    "| randomforest | 3.65455 | \n",
    "| randomforest+validation | 3.65173 | \n",
    "| LightGBM | 3.69723 |\n",
    "| LightGBM+validation | 3.64403 |\n",
    "| XGBoost | 3.62832 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49bcc18-ac13-4252-aca7-1cf441898db1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748f25b-9ef3-45da-ad06-5a090a3ed6a1",
   "metadata": {},
   "source": [
    "# Ensemble training\n",
    "## Voting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049937b5",
   "metadata": {},
   "source": [
    "Voting can be simply implemented weighted sum of results from models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca15c86-0b44-4fdc-ae28-6c2cbabf062c",
   "metadata": {},
   "source": [
    "### 1.Voting with average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2964118f-c632-4878-97db-14e0e47b0477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                target  randomforest  lightgbm   xgboost\n",
      "target        1.000000      1.000000  0.956251  0.947529\n",
      "randomforest  1.000000      1.000000  0.956251  0.947529\n",
      "lightgbm      0.956251      0.956251  1.000000  0.951461\n",
      "xgboost       0.947529      0.947529  0.951461  1.000000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./result/submission_randomforest.csv\")\n",
    "data['randomforest'] = data['target'].values\n",
    "\n",
    "temp = pd.read_csv(\"./result/submission_lightgbm.csv\")\n",
    "data['lightgbm'] = temp['target'].values\n",
    "\n",
    "\n",
    "temp = pd.read_csv(\"./result/submission_xgboost.csv\")\n",
    "data['xgboost'] = temp['target'].values\n",
    "\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "012ddc2d-3046-4a00-9b48-649ab3145a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "      <th>randomforest</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-3.528347</td>\n",
       "      <td>-3.528347</td>\n",
       "      <td>-3.576328</td>\n",
       "      <td>-3.737840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.789489</td>\n",
       "      <td>-0.789489</td>\n",
       "      <td>-0.866846</td>\n",
       "      <td>-0.540275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.380266</td>\n",
       "      <td>-0.380266</td>\n",
       "      <td>-0.370968</td>\n",
       "      <td>-0.433453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.269844</td>\n",
       "      <td>-0.269844</td>\n",
       "      <td>-0.121097</td>\n",
       "      <td>-0.176081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-1.038557</td>\n",
       "      <td>-1.038557</td>\n",
       "      <td>-1.047017</td>\n",
       "      <td>-1.027519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target  randomforest  lightgbm   xgboost\n",
       "0  C_ID_0ab67a22ab -3.528347     -3.528347 -3.576328 -3.737840\n",
       "1  C_ID_130fd0cbdd -0.789489     -0.789489 -0.866846 -0.540275\n",
       "2  C_ID_b709037bc5 -0.380266     -0.380266 -0.370968 -0.433453\n",
       "3  C_ID_d27d835a9f -0.269844     -0.269844 -0.121097 -0.176081\n",
       "4  C_ID_2b5e3df5c2 -1.038557     -1.038557 -1.047017 -1.027519"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "32aa3998-d98f-4984-b423-81c9e2a7fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = (data['randomforest'] + data['lightgbm'] + data['xgboost']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6b920210-db28-4f67-b7d7-3fa0c136b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['card_id','target']].to_csv(\"result/voting_avr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da6e5c-66c2-4813-9f44-a1c22c8d9b1a",
   "metadata": {},
   "source": [
    "| Approach | RMSE |\n",
    "| -- | -- |\n",
    "| Base line | 3.65455 |\n",
    "| RF + CV | 3.65173 |\n",
    "| LightGBM | 3.69732 |\n",
    "| LightGBM + CV| 3.64403 |\n",
    "| XGBoost | 3.62832 |\n",
    "| Average Voting | 3.6365 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc77d30-3df2-4c89-a8f2-e7cfb1db79a2",
   "metadata": {},
   "source": [
    "### 2. Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6371765-9cb0-44a9-a8c1-34313e1e8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['randomforest']*0.2+data['lightgbm']*0.3 + data['xgboost']*0.5\n",
    "data[['card_id','target']].to_csv(\"result/voting_wei1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f866ac-bdf4-4469-b150-635a2219d6d0",
   "metadata": {},
   "source": [
    "| Approach | RMSE |\n",
    "| -- | -- |\n",
    "| Base line | 3.65455 |\n",
    "| RF + CV | 3.65173 |\n",
    "| LightGBM | 3.69732 |\n",
    "| LightGBM + CV| 3.64403 |\n",
    "| XGBoost | 3.62832 |\n",
    "| Average Voting | 3.6365 |\n",
    "| weighted Voting | 3.633307 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4390e40-ee15-4b07-bb73-a1db53856d8c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ae21a-5c39-4017-b919-ed36e06b1235",
   "metadata": {},
   "source": [
    "## Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03614ed9-ed4a-478e-be51-d188d6e54730",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_rf  = pd.read_csv('./dataset/preprocess/train_randomforest.csv')\n",
    "predictions_rf  = pd.read_csv('./dataset/preprocess/test_randomforest.csv')\n",
    "\n",
    "oof_lgb  = pd.read_csv('./dataset/preprocess/train_lightgbm.csv')\n",
    "predictions_lgb  = pd.read_csv('./dataset/preprocess/test_lightgbm.csv')\n",
    "\n",
    "oof_xgb  = pd.read_csv('./dataset/preprocess/train_xgboost.csv')\n",
    "predictions_xgb  = pd.read_csv('./dataset/preprocess/test_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d4fb075d-480c-4752-bfc8-262f5261d1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.426984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.857115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.063488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.278658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0 -0.426984\n",
       "1 -1.857115\n",
       "2  0.402431\n",
       "3 -0.063488\n",
       "4 -0.278658"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_rf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6b95102-00ba-471a-9cf6-cb527399502e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.576328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.866846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.370968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.121097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.047017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0 -3.576328\n",
       "1 -0.866846\n",
       "2 -0.370968\n",
       "3 -0.121097\n",
       "4 -1.047017"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lgb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8f2ef663-3a4e-41be-abce-c30cbbd17728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((201917, 1), (201917, 1))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_rf.shape, oof_lgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "47f56584-ac6e-4875-8ac4-1feda0be002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123623, 1), (123623, 1))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rf.shape, predictions_lgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25a4a93e-dbb8-4a4a-b999-eae6b7279aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_model(oof_1, oof_2, oof_3, predictions_1, predictions_2, predictions_3, y):\n",
    "   \n",
    "    # Part 1.数据准备\n",
    "    # 按行拼接列，拼接验证集所有预测结果\n",
    "    # train_stack就是final model的训练数据\n",
    "    train_stack = np.hstack([oof_1, oof_2, oof_3])\n",
    "    # 按行拼接列，拼接测试集上所有预测结果\n",
    "    # test_stack就是final model的测试数据\n",
    "    test_stack = np.hstack([predictions_1, predictions_2, predictions_3])\n",
    "    # 创建一个和验证集行数相同的全零数组\n",
    "    # oof = np.zeros(train_stack.shape[0])\n",
    "    # 创建一个和测试集行数相同的全零数组\n",
    "    predictions = np.zeros(test_stack.shape[0])\n",
    "    \n",
    "    # Part 2.多轮交叉验证\n",
    "    from sklearn.model_selection import RepeatedKFold\n",
    "    folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=2020)\n",
    "    \n",
    "    # fold_为折数，trn_idx为每一折训练集index，val_idx为每一折验证集index\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_stack, y)):\n",
    "        # 打印折数信息\n",
    "        print(\"fold n°{}\".format(fold_+1))\n",
    "        # 训练集中划分为训练数据的特征和标签\n",
    "        trn_data, trn_y = train_stack[trn_idx], y[trn_idx]\n",
    "        # 训练集中划分为验证数据的特征和标签\n",
    "        val_data, val_y = train_stack[val_idx], y[val_idx]\n",
    "        # 开始训练时提示\n",
    "        print(\"-\" * 10 + \"Stacking \" + str(fold_+1) + \"-\" * 10)\n",
    "        # 采用贝叶斯回归作为结果融合的模型（final model）\n",
    "        clf = BayesianRidge()\n",
    "        # 在训练数据上进行训练\n",
    "        clf.fit(trn_data, trn_y)\n",
    "        # 在验证数据上进行预测，并将结果记录在oof对应位置\n",
    "        # oof[val_idx] = clf.predict(val_data)\n",
    "        # 对测试集数据进行预测，每一轮预测结果占比额外的1/10\n",
    "        predictions += clf.predict(test_stack) / (5 * 2)\n",
    "    \n",
    "    # 返回测试集的预测结果\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40205135-6346-4ce3-9dea-5fcf01915ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04ed450d-6bc8-4d4c-8193-12f325badfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "----------Stacking 1----------\n",
      "fold n°2\n",
      "----------Stacking 2----------\n",
      "fold n°3\n",
      "----------Stacking 3----------\n",
      "fold n°4\n",
      "----------Stacking 4----------\n",
      "fold n°5\n",
      "----------Stacking 5----------\n",
      "fold n°6\n",
      "----------Stacking 6----------\n",
      "fold n°7\n",
      "----------Stacking 7----------\n",
      "fold n°8\n",
      "----------Stacking 8----------\n",
      "fold n°9\n",
      "----------Stacking 9----------\n",
      "fold n°10\n",
      "----------Stacking 10----------\n"
     ]
    }
   ],
   "source": [
    "predictions_stack  = stack_model(oof_rf, oof_lgb, oof_xgb, \n",
    "                                 predictions_rf, predictions_lgb, predictions_xgb, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98c8f593-bb50-4084-b746-22f60ad2b9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.05848444, -0.68964305, -0.41582154, ...,  0.65614588,\n",
       "       -2.35990886,  0.39282516])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "237aa9dc-01a8-4b0a-961b-4cb3303b1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('data/sample_submission.csv')\n",
    "sub_df[\"target\"] = predictions_stack\n",
    "sub_df.to_csv('predictions_stack1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ecaa9-ef5d-448f-83cd-1537fdfbe416",
   "metadata": {},
   "source": [
    "| Approach | RMSE |\n",
    "| -- | -- |\n",
    "| Base line | 3.65455 |\n",
    "| RF + CV | 3.65173 |\n",
    "| LightGBM | 3.69732 |\n",
    "| LightGBM + CV| 3.64403 |\n",
    "| XGBoost | 3.62832 |\n",
    "| Average Voting | 3.6365 |\n",
    "| weighted Voting | 3.633307 |\n",
    "| Stacking | 3.62798 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
