{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import f_regression\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper feature selection, LightGBM, TPE tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/preprocess/train.csv')\n",
    "test = pd.read_csv('./dataset/preprocess/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a LightGBM model with 5 folds cross validation, and calculate most important 300 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select_wrapper(train, test):\n",
    "    \"\"\"\n",
    "    Feature selection by LGBM\n",
    "    :param train:\n",
    "    :param test:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Part 1.划分特征名称，删除ID列和标签列\n",
    "    print('feature_select_wrapper...')\n",
    "    label = 'target'\n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "\n",
    "    # Step 2.配置lgb参数\n",
    "    # 模型参数\n",
    "    params_initial = {\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'boosting': 'gbdt',\n",
    "        'min_child_samples': 20,\n",
    "        'bagging_seed': 2020,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 1,\n",
    "        'feature_fraction': 0.7,\n",
    "        'max_depth': -1,\n",
    "        'metric': 'rmse',\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 1,\n",
    "        'objective': 'regression',\n",
    "        'verbose': 1\n",
    "    }\n",
    "    # 控制参数\n",
    "    # 提前验证迭代效果或停止\n",
    "    ESR = 30\n",
    "    # 迭代次数\n",
    "    NBR = 10000\n",
    "    # 打印间隔\n",
    "    VBE = 50\n",
    "    \n",
    "    # Part 3.交叉验证过程\n",
    "    # 实例化评估器\n",
    "    kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    # 创建空容器\n",
    "    fse = pd.Series(0, index=features)\n",
    "    \n",
    "    for train_part_index, eval_index in kf.split(train[features], train[label]):\n",
    "        # 封装训练数据集\n",
    "        train_part = lgb.Dataset(train[features].loc[train_part_index],\n",
    "                                 train[label].loc[train_part_index])\n",
    "        # 封装验证数据集\n",
    "        eval = lgb.Dataset(train[features].loc[eval_index],\n",
    "                           train[label].loc[eval_index])\n",
    "        # 在训练集上进行训练，并同时进行验证\n",
    "        bst = lgb.train(params_initial, train_part, num_boost_round=NBR,\n",
    "                        valid_sets=[train_part, eval],\n",
    "                        valid_names=['train', 'valid'])\n",
    "        # 输出特征重要性计算结果，并进行累加\n",
    "        fse += pd.Series(bst.feature_importance(), features)\n",
    "    \n",
    "    # Part 4.选择最重要的300个特征\n",
    "    feature_select = ['card_id'] + fse.sort_values(ascending=False).index.tolist()[:300]\n",
    "    print('done')\n",
    "    return train[feature_select + ['target']], test[feature_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_select_wrapper...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227016\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1626\n",
      "[LightGBM] [Info] Start training from score -0.390986\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.638084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227122\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1629\n",
      "[LightGBM] [Info] Start training from score -0.396781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.657010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227089\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1631\n",
      "[LightGBM] [Info] Start training from score -0.390348\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.676778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227023\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1624\n",
      "[LightGBM] [Info] Start training from score -0.391392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.674675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227023\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1625\n",
      "[LightGBM] [Info] Start training from score -0.398675\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_LGBM, test_LGBM = feature_select_wrapper(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 302)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_LGBM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the LightGBM model and TPE optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those hyperparameters we don't want use the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_append(params):\n",
    "    \"\"\"\n",
    "    动态回调参数函数，params视作字典\n",
    "    :param params:lgb参数字典\n",
    "    :return params:修正后的lgb参数字典\n",
    "    \"\"\"\n",
    "    params['feature_pre_filter'] = False\n",
    "    params['objective'] = 'regression'\n",
    "    params['metric'] = 'rmse'\n",
    "    params['bagging_seed'] = 2020,\n",
    "    params['verbose'] = -1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_hyperopt(train):\n",
    "    label = 'target'\n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "\n",
    "    train_data = lgb.Dataset(train[features], train[label])\n",
    "\n",
    "    def hyperopt_objective(params):\n",
    "        \"\"\"\n",
    "        input hyperparameters, output associated loss\n",
    "        :params: params\n",
    "        :return: minimum rmse\n",
    "        \"\"\"\n",
    "        params = params_append(params)\n",
    "        print(params)\n",
    "\n",
    "        # Define the early stopping callback function\n",
    "        early_stopping_callback = lgb.early_stopping(20)\n",
    "        # Define a callback function to print the standard deviation of the cross-validation scores\n",
    "        # def print_stdv(cv_results):\n",
    "        #     cv_results = cv_results.get_cv_folds_results()\n",
    "        #     print('Standard deviation of cross-validation scores:', np.std(cv_results['rmse-mean']))\n",
    "        res = lgb.cv(params, train_data, 1000,\n",
    "                     nfold=2,\n",
    "                     stratified=False,\n",
    "                     shuffle=True,\n",
    "                     metrics='rmse',\n",
    "                     callbacks=[early_stopping_callback],\n",
    "                     eval_train_metric=False,\n",
    "                     seed=2020)\n",
    "        #print(res)\n",
    "        return min(res['valid rmse-mean']) # res is a dict\n",
    "    \n",
    "    params_space = {\n",
    "        'learning_rate': hp.uniform('learning_rate', 1e-2, 5e-1),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n",
    "        'num_leaves': hp.choice('num_leaves', list(range(10, 300, 10))),\n",
    "        'reg_alpha': hp.randint('reg_alpha', 0, 10),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0, 10),\n",
    "        'bagging_freq': hp.randint('bagging_freq', 1, 10),\n",
    "        'min_child_samples': hp.choice('min_child_samples', list(range(1, 30, 5)))\n",
    "    }\n",
    "\n",
    "    params_best = fmin(\n",
    "        hyperopt_objective,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=30,\n",
    "        rstate=np.random.default_rng(2020))\n",
    "    \n",
    "    # 返回最佳参数\n",
    "    return params_best\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.9429104308567877, 'bagging_freq': 2, 'feature_fraction': 0.5715782198140802, 'learning_rate': 0.21315219327595428, 'min_child_samples': 11, 'num_leaves': 160, 'reg_alpha': 3, 'reg_lambda': 7.561160634893758, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931 \n",
      "[LightGBM] [Info] Start training from score -0.390344 \n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:                    \n",
      "[8]\tcv_agg's valid rmse: 3.74033 + 0.00792729\n",
      "{'bagging_fraction': 0.512262561313273, 'bagging_freq': 3, 'feature_fraction': 0.6864235320941958, 'learning_rate': 0.31527024380943564, 'min_child_samples': 1, 'num_leaves': 180, 'reg_alpha': 2, 'reg_lambda': 7.569488156706784, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[3]\tcv_agg's valid rmse: 3.79314 + 0.00208183\n",
      "{'bagging_fraction': 0.8893476235428235, 'bagging_freq': 7, 'feature_fraction': 0.7135664981551813, 'learning_rate': 0.2903641143253666, 'min_child_samples': 21, 'num_leaves': 210, 'reg_alpha': 8, 'reg_lambda': 5.393157199547058, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[4]\tcv_agg's valid rmse: 3.76136 + 0.00596464\n",
      "{'bagging_fraction': 0.6787796182704178, 'bagging_freq': 1, 'feature_fraction': 0.7013446622253534, 'learning_rate': 0.4739191471915275, 'min_child_samples': 21, 'num_leaves': 190, 'reg_alpha': 0, 'reg_lambda': 7.368279836937887, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[1]\tcv_agg's valid rmse: 3.79692 + 0.0101831\n",
      "{'bagging_fraction': 0.7626783188810151, 'bagging_freq': 6, 'feature_fraction': 0.8391402503316614, 'learning_rate': 0.36741303605044506, 'min_child_samples': 26, 'num_leaves': 40, 'reg_alpha': 4, 'reg_lambda': 9.629414851907006, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.166547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[8]\tcv_agg's valid rmse: 3.73821 + 0.00899502\n",
      "{'bagging_fraction': 0.7897880317843915, 'bagging_freq': 1, 'feature_fraction': 0.6864530344942663, 'learning_rate': 0.16801009574165351, 'min_child_samples': 6, 'num_leaves': 160, 'reg_alpha': 6, 'reg_lambda': 7.928417982876395, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[13]\tcv_agg's valid rmse: 3.74404 + 0.0137494\n",
      "{'bagging_fraction': 0.5709455293113112, 'bagging_freq': 6, 'feature_fraction': 0.6817716125366499, 'learning_rate': 0.28149790303677774, 'min_child_samples': 26, 'num_leaves': 50, 'reg_alpha': 2, 'reg_lambda': 0.9202721245005685, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[7]\tcv_agg's valid rmse: 3.75433 + 0.0164256\n",
      "{'bagging_fraction': 0.8894268166893926, 'bagging_freq': 7, 'feature_fraction': 0.8614864228571265, 'learning_rate': 0.10838878622896095, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 7, 'reg_lambda': 4.128216047488188, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.173755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[42]\tcv_agg's valid rmse: 3.7145 + 0.00505005\n",
      "{'bagging_fraction': 0.8689240389616162, 'bagging_freq': 6, 'feature_fraction': 0.8839374526657198, 'learning_rate': 0.1295409886684552, 'min_child_samples': 1, 'num_leaves': 120, 'reg_alpha': 1, 'reg_lambda': 0.8934485689740768, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.170205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.166662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[15]\tcv_agg's valid rmse: 3.74741 + 0.0101397\n",
      "{'bagging_fraction': 0.9827696256425138, 'bagging_freq': 6, 'feature_fraction': 0.6241629598983252, 'learning_rate': 0.2693431830624993, 'min_child_samples': 11, 'num_leaves': 30, 'reg_alpha': 7, 'reg_lambda': 5.653589408911715, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[18]\tcv_agg's valid rmse: 3.7252 + 0.00300962\n",
      "{'bagging_fraction': 0.5890956497689592, 'bagging_freq': 8, 'feature_fraction': 0.9337630517879247, 'learning_rate': 0.1227160059413021, 'min_child_samples': 6, 'num_leaves': 220, 'reg_alpha': 2, 'reg_lambda': 0.31991676687450954, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[10]\tcv_agg's valid rmse: 3.77585 + 0.0130239\n",
      "{'bagging_fraction': 0.8729748815879685, 'bagging_freq': 2, 'feature_fraction': 0.6729872738023669, 'learning_rate': 0.28953159858971855, 'min_child_samples': 1, 'num_leaves': 250, 'reg_alpha': 9, 'reg_lambda': 4.085962466064952, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[4]\tcv_agg's valid rmse: 3.78753 + 0.00534837\n",
      "{'bagging_fraction': 0.7309889558300577, 'bagging_freq': 5, 'feature_fraction': 0.8837040135439155, 'learning_rate': 0.31983542597602754, 'min_child_samples': 26, 'num_leaves': 260, 'reg_alpha': 8, 'reg_lambda': 6.723833935558674, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[4]\tcv_agg's valid rmse: 3.76304 + 0.00298753\n",
      "{'bagging_fraction': 0.9667073801956272, 'bagging_freq': 7, 'feature_fraction': 0.8411933464820867, 'learning_rate': 0.10280030920385813, 'min_child_samples': 11, 'num_leaves': 270, 'reg_alpha': 9, 'reg_lambda': 3.059522549630802, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[18]\tcv_agg's valid rmse: 3.735 + 0.013446\n",
      "{'bagging_fraction': 0.6843213475295423, 'bagging_freq': 4, 'feature_fraction': 0.7924623289134336, 'learning_rate': 0.3020635372075119, 'min_child_samples': 16, 'num_leaves': 120, 'reg_alpha': 6, 'reg_lambda': 2.0996363046714714, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.77194 + 0.0034647\n",
      "{'bagging_fraction': 0.7318956453136132, 'bagging_freq': 9, 'feature_fraction': 0.5776201196248023, 'learning_rate': 0.3717731127680832, 'min_child_samples': 6, 'num_leaves': 80, 'reg_alpha': 3, 'reg_lambda': 4.470202857823412, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.78062 + 0.013393\n",
      "{'bagging_fraction': 0.7641897846788224, 'bagging_freq': 3, 'feature_fraction': 0.6509590691041207, 'learning_rate': 0.3065257082129887, 'min_child_samples': 26, 'num_leaves': 160, 'reg_alpha': 5, 'reg_lambda': 1.776182232691963, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.76393 + 0.00976616\n",
      "{'bagging_fraction': 0.9370719655323888, 'bagging_freq': 4, 'feature_fraction': 0.6972885246773278, 'learning_rate': 0.4259177413670385, 'min_child_samples': 21, 'num_leaves': 100, 'reg_alpha': 9, 'reg_lambda': 9.310430097750862, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.7605 + 0.0133465\n",
      "{'bagging_fraction': 0.9699889069149303, 'bagging_freq': 3, 'feature_fraction': 0.8494538930974609, 'learning_rate': 0.3302708934751551, 'min_child_samples': 16, 'num_leaves': 130, 'reg_alpha': 9, 'reg_lambda': 3.9562017043556583, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.76515 + 0.0099278\n",
      "{'bagging_fraction': 0.8133108300550449, 'bagging_freq': 8, 'feature_fraction': 0.539933748479144, 'learning_rate': 0.04470502280634237, 'min_child_samples': 11, 'num_leaves': 290, 'reg_alpha': 5, 'reg_lambda': 0.1666976761518424, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.154853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.146861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[44]\tcv_agg's valid rmse: 3.71803 + 0.00877634\n",
      "{'bagging_fraction': 0.8198879482271282, 'bagging_freq': 8, 'feature_fraction': 0.5135156001738832, 'learning_rate': 0.014657097603624963, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 7, 'reg_lambda': 2.7194579245643924, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[398]\tcv_agg's valid rmse: 3.68796 + 0.008515\n",
      "{'bagging_fraction': 0.8294298120868376, 'bagging_freq': 8, 'feature_fraction': 0.9671624694505763, 'learning_rate': 0.052805028235069856, 'min_child_samples': 16, 'num_leaves': 230, 'reg_alpha': 7, 'reg_lambda': 2.9937995575392815, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[34]\tcv_agg's valid rmse: 3.71832 + 0.00916866\n",
      "{'bagging_fraction': 0.9088260727738453, 'bagging_freq': 7, 'feature_fraction': 0.7682838434935467, 'learning_rate': 0.016230802511972717, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 7, 'reg_lambda': 2.7650949078420686, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[406]\tcv_agg's valid rmse: 3.68853 + 0.00620454\n",
      "{'bagging_fraction': 0.9177022453415298, 'bagging_freq': 7, 'feature_fraction': 0.775586846193078, 'learning_rate': 0.02964793258923834, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 7, 'reg_lambda': 2.848195902638218, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[224]\tcv_agg's valid rmse: 3.69221 + 0.0105\n",
      "{'bagging_fraction': 0.8410481944077957, 'bagging_freq': 8, 'feature_fraction': 0.7499075612116564, 'learning_rate': 0.013556362940723859, 'min_child_samples': 16, 'num_leaves': 280, 'reg_alpha': 7, 'reg_lambda': 1.8916969966980561, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[210]\tcv_agg's valid rmse: 3.69724 + 0.0114016\n",
      "{'bagging_fraction': 0.6892012119502908, 'bagging_freq': 9, 'feature_fraction': 0.5156046004363076, 'learning_rate': 0.21214389733281974, 'min_child_samples': 16, 'num_leaves': 150, 'reg_alpha': 7, 'reg_lambda': 6.18847005457185, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[7]\tcv_agg's valid rmse: 3.76042 + 0.00649016\n",
      "{'bagging_fraction': 0.6272369909079323, 'bagging_freq': 5, 'feature_fraction': 0.7449032523357751, 'learning_rate': 0.06791374441702488, 'min_child_samples': 16, 'num_leaves': 200, 'reg_alpha': 0, 'reg_lambda': 3.3416874863644837, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[35]\tcv_agg's valid rmse: 3.72662 + 0.00742824\n",
      "{'bagging_fraction': 0.7966647756833211, 'bagging_freq': 7, 'feature_fraction': 0.6184070212810147, 'learning_rate': 0.19383501258362018, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 4, 'reg_lambda': 1.2143934086155816, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.170145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[16]\tcv_agg's valid rmse: 3.73637 + 0.00439409\n",
      "{'bagging_fraction': 0.9960399841724703, 'bagging_freq': 8, 'feature_fraction': 0.801734312459067, 'learning_rate': 0.15880386075925276, 'min_child_samples': 16, 'num_leaves': 140, 'reg_alpha': 3, 'reg_lambda': 4.87837731863211, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[15]\tcv_agg's valid rmse: 3.73978 + 0.00787421\n",
      "{'bagging_fraction': 0.919983174955275, 'bagging_freq': 2, 'feature_fraction': 0.5809795191613055, 'learning_rate': 0.23887137836875277, 'min_child_samples': 16, 'num_leaves': 60, 'reg_alpha': 7, 'reg_lambda': 2.526217027086027, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.154304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[10]\tcv_agg's valid rmse: 3.74192 + 0.0165366\n",
      "100%|██████████| 30/30 [04:31<00:00,  9.04s/trial, best loss: 3.6879642084107567]\n"
     ]
    }
   ],
   "source": [
    "best_clf = param_hyperopt(train_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.8198879482271282,\n",
       " 'bagging_freq': 8,\n",
       " 'feature_fraction': 0.5135156001738832,\n",
       " 'learning_rate': 0.014657097603624963,\n",
       " 'min_child_samples': 3,\n",
       " 'num_leaves': 6,\n",
       " 'reg_alpha': 7,\n",
       " 'reg_lambda': 2.7194579245643924}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM predition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = params_append(best_clf)\n",
    "\n",
    "label = 'target'\n",
    "features = train_LGBM.columns.tolist()\n",
    "features.remove('card_id')\n",
    "features.remove('target')\n",
    "\n",
    "lgb_train = lgb.Dataset(train_LGBM[features], train_LGBM[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.319097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405\n",
      "[LightGBM] [Info] Number of data points in the train set: 201917, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.393636\n"
     ]
    }
   ],
   "source": [
    "bst = lgb.train(best_clf, lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22620818, -1.25457104,  0.04399539, ..., -0.26112611,\n",
       "       -1.06688101, -0.22620818])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.predict(train_LGBM[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.731340064698996"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(train_LGBM[label], bst.predict(train_LGBM[features])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\3110385309.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_LGBM['target'] = bst.predict(test_LGBM[features])\n"
     ]
    }
   ],
   "source": [
    "test_LGBM['target'] = bst.predict(test_LGBM[features])\n",
    "test_LGBM[['card_id', 'target']].to_csv(\"./result/submission_LGBM_single.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.084191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.670433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.095542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.221292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-0.286112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.084191\n",
       "1  C_ID_130fd0cbdd -0.670433\n",
       "2  C_ID_b709037bc5 -0.095542\n",
       "3  C_ID_d27d835a9f -0.221292\n",
       "4  C_ID_2b5e3df5c2 -0.286112"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_LGBM[['card_id', 'target']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(train, test, params):\n",
    "    \"\"\"\n",
    "    :param train:\n",
    "    :param test:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    label = 'target'\n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "    \n",
    "    params = params_append(params)\n",
    "    ESR = 30\n",
    "    NBR = 10000\n",
    "    VBE = 50\n",
    "    \n",
    "    prediction_test = 0\n",
    "    cv_score = []\n",
    "    prediction_train = pd.Series()\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "\n",
    "    for train_part_index, eval_index in kf.split(train[features], train[label]):\n",
    "        train_part = lgb.Dataset(train[features].loc[train_part_index],\n",
    "                                 train[label].loc[train_part_index])\n",
    "        eval = lgb.Dataset(train[features].loc[eval_index],\n",
    "                           train[label].loc[eval_index])\n",
    "        early_stopping_callback = lgb.early_stopping(20)\n",
    "        bst = lgb.train(params, train_part, num_boost_round=NBR,\n",
    "                        valid_sets=[train_part, eval],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        callbacks=[early_stopping_callback])\n",
    "        # 测试集预测结果并纳入prediction_test容器\n",
    "        prediction_test += bst.predict(test[features])\n",
    "        # 验证集预测结果并纳入prediction_train容器\n",
    "        prediction_train = prediction_train.append(pd.Series(bst.predict(train[features].loc[eval_index]),\n",
    "                                                             index=eval_index))\n",
    "        # 验证集预测结果\n",
    "        eval_pre = bst.predict(train[features].loc[eval_index])\n",
    "        # 计算验证集上得分\n",
    "        score = np.sqrt(mean_squared_error(train[label].loc[eval_index].values, eval_pre))\n",
    "        # 纳入cv_score容器\n",
    "        cv_score.append(score)\n",
    "        \n",
    "    print(cv_score, sum(cv_score) / 5)\n",
    "    pd.Series(prediction_train.sort_index().values).to_csv(\"./dataset/preprocess/train_lightgbm.csv\", index=False)\n",
    "    pd.Series(prediction_test / 5).to_csv(\"./dataset/preprocess/test_lightgbm.csv\", index=False)\n",
    "    test['target'] = prediction_test / 5\n",
    "    test[['card_id', 'target']].to_csv(\"./result/submission_lightgbm_cv.csv\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_select_wrapper...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.711466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227016\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1626\n",
      "[LightGBM] [Info] Start training from score -0.390986\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227122\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1629\n",
      "[LightGBM] [Info] Start training from score -0.396781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.755185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227089\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1631\n",
      "[LightGBM] [Info] Start training from score -0.390348\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.724745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227023\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1624\n",
      "[LightGBM] [Info] Start training from score -0.391392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.695784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227023\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1625\n",
      "[LightGBM] [Info] Start training from score -0.398675\n",
      "done\n",
      "{'bagging_fraction': 0.9429104308567877, 'bagging_freq': 2, 'feature_fraction': 0.5715782198140802, 'learning_rate': 0.21315219327595428, 'min_child_samples': 11, 'num_leaves': 160, 'reg_alpha': 3, 'reg_lambda': 7.561160634893758, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931 \n",
      "[LightGBM] [Info] Start training from score -0.390344 \n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:                    \n",
      "[8]\tcv_agg's valid rmse: 3.74033 + 0.00792729\n",
      "{'bagging_fraction': 0.512262561313273, 'bagging_freq': 3, 'feature_fraction': 0.6864235320941958, 'learning_rate': 0.31527024380943564, 'min_child_samples': 1, 'num_leaves': 180, 'reg_alpha': 2, 'reg_lambda': 7.569488156706784, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[3]\tcv_agg's valid rmse: 3.79314 + 0.00208183\n",
      "{'bagging_fraction': 0.8893476235428235, 'bagging_freq': 7, 'feature_fraction': 0.7135664981551813, 'learning_rate': 0.2903641143253666, 'min_child_samples': 21, 'num_leaves': 210, 'reg_alpha': 8, 'reg_lambda': 5.393157199547058, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[4]\tcv_agg's valid rmse: 3.76136 + 0.00596464\n",
      "{'bagging_fraction': 0.6787796182704178, 'bagging_freq': 1, 'feature_fraction': 0.7013446622253534, 'learning_rate': 0.4739191471915275, 'min_child_samples': 21, 'num_leaves': 190, 'reg_alpha': 0, 'reg_lambda': 7.368279836937887, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[1]\tcv_agg's valid rmse: 3.79692 + 0.0101831\n",
      "{'bagging_fraction': 0.7626783188810151, 'bagging_freq': 6, 'feature_fraction': 0.8391402503316614, 'learning_rate': 0.36741303605044506, 'min_child_samples': 26, 'num_leaves': 40, 'reg_alpha': 4, 'reg_lambda': 9.629414851907006, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[8]\tcv_agg's valid rmse: 3.73821 + 0.00899502\n",
      "{'bagging_fraction': 0.7897880317843915, 'bagging_freq': 1, 'feature_fraction': 0.6864530344942663, 'learning_rate': 0.16801009574165351, 'min_child_samples': 6, 'num_leaves': 160, 'reg_alpha': 6, 'reg_lambda': 7.928417982876395, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[13]\tcv_agg's valid rmse: 3.74404 + 0.0137494\n",
      "{'bagging_fraction': 0.5709455293113112, 'bagging_freq': 6, 'feature_fraction': 0.6817716125366499, 'learning_rate': 0.28149790303677774, 'min_child_samples': 26, 'num_leaves': 50, 'reg_alpha': 2, 'reg_lambda': 0.9202721245005685, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[7]\tcv_agg's valid rmse: 3.75433 + 0.0164256\n",
      "{'bagging_fraction': 0.8894268166893926, 'bagging_freq': 7, 'feature_fraction': 0.8614864228571265, 'learning_rate': 0.10838878622896095, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 7, 'reg_lambda': 4.128216047488188, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[42]\tcv_agg's valid rmse: 3.7145 + 0.00505005\n",
      "{'bagging_fraction': 0.8689240389616162, 'bagging_freq': 6, 'feature_fraction': 0.8839374526657198, 'learning_rate': 0.1295409886684552, 'min_child_samples': 1, 'num_leaves': 120, 'reg_alpha': 1, 'reg_lambda': 0.8934485689740768, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[15]\tcv_agg's valid rmse: 3.74741 + 0.0101397\n",
      "{'bagging_fraction': 0.9827696256425138, 'bagging_freq': 6, 'feature_fraction': 0.6241629598983252, 'learning_rate': 0.2693431830624993, 'min_child_samples': 11, 'num_leaves': 30, 'reg_alpha': 7, 'reg_lambda': 5.653589408911715, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "Training until validation scores don't improve for 20 rounds                    \n",
      "Early stopping, best iteration is:                                              \n",
      "[18]\tcv_agg's valid rmse: 3.7252 + 0.00300962\n",
      "{'bagging_fraction': 0.5890956497689592, 'bagging_freq': 8, 'feature_fraction': 0.9337630517879247, 'learning_rate': 0.1227160059413021, 'min_child_samples': 6, 'num_leaves': 220, 'reg_alpha': 2, 'reg_lambda': 0.31991676687450954, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[10]\tcv_agg's valid rmse: 3.77585 + 0.0130239\n",
      "{'bagging_fraction': 0.8729748815879685, 'bagging_freq': 2, 'feature_fraction': 0.6729872738023669, 'learning_rate': 0.28953159858971855, 'min_child_samples': 1, 'num_leaves': 250, 'reg_alpha': 9, 'reg_lambda': 4.085962466064952, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[4]\tcv_agg's valid rmse: 3.78753 + 0.00534837\n",
      "{'bagging_fraction': 0.7309889558300577, 'bagging_freq': 5, 'feature_fraction': 0.8837040135439155, 'learning_rate': 0.31983542597602754, 'min_child_samples': 26, 'num_leaves': 260, 'reg_alpha': 8, 'reg_lambda': 6.723833935558674, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[4]\tcv_agg's valid rmse: 3.76304 + 0.00298753\n",
      "{'bagging_fraction': 0.9667073801956272, 'bagging_freq': 7, 'feature_fraction': 0.8411933464820867, 'learning_rate': 0.10280030920385813, 'min_child_samples': 11, 'num_leaves': 270, 'reg_alpha': 9, 'reg_lambda': 3.059522549630802, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.201161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[18]\tcv_agg's valid rmse: 3.735 + 0.013446\n",
      "{'bagging_fraction': 0.6843213475295423, 'bagging_freq': 4, 'feature_fraction': 0.7924623289134336, 'learning_rate': 0.3020635372075119, 'min_child_samples': 16, 'num_leaves': 120, 'reg_alpha': 6, 'reg_lambda': 2.0996363046714714, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.77194 + 0.0034647\n",
      "{'bagging_fraction': 0.7318956453136132, 'bagging_freq': 9, 'feature_fraction': 0.5776201196248023, 'learning_rate': 0.3717731127680832, 'min_child_samples': 6, 'num_leaves': 80, 'reg_alpha': 3, 'reg_lambda': 4.470202857823412, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.171423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.78062 + 0.013393\n",
      "{'bagging_fraction': 0.7641897846788224, 'bagging_freq': 3, 'feature_fraction': 0.6509590691041207, 'learning_rate': 0.3065257082129887, 'min_child_samples': 26, 'num_leaves': 160, 'reg_alpha': 5, 'reg_lambda': 1.776182232691963, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.76393 + 0.00976616\n",
      "{'bagging_fraction': 0.9370719655323888, 'bagging_freq': 4, 'feature_fraction': 0.6972885246773278, 'learning_rate': 0.4259177413670385, 'min_child_samples': 21, 'num_leaves': 100, 'reg_alpha': 9, 'reg_lambda': 9.310430097750862, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.7605 + 0.0133465\n",
      "{'bagging_fraction': 0.9699889069149303, 'bagging_freq': 3, 'feature_fraction': 0.8494538930974609, 'learning_rate': 0.3302708934751551, 'min_child_samples': 16, 'num_leaves': 130, 'reg_alpha': 9, 'reg_lambda': 3.9562017043556583, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[3]\tcv_agg's valid rmse: 3.76515 + 0.0099278\n",
      "{'bagging_fraction': 0.8133108300550449, 'bagging_freq': 8, 'feature_fraction': 0.539933748479144, 'learning_rate': 0.04470502280634237, 'min_child_samples': 11, 'num_leaves': 290, 'reg_alpha': 5, 'reg_lambda': 0.1666976761518424, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.170658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[44]\tcv_agg's valid rmse: 3.71803 + 0.00877634\n",
      "{'bagging_fraction': 0.8198879482271282, 'bagging_freq': 8, 'feature_fraction': 0.5135156001738832, 'learning_rate': 0.014657097603624963, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 7, 'reg_lambda': 2.7194579245643924, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[398]\tcv_agg's valid rmse: 3.68796 + 0.008515\n",
      "{'bagging_fraction': 0.8294298120868376, 'bagging_freq': 8, 'feature_fraction': 0.9671624694505763, 'learning_rate': 0.052805028235069856, 'min_child_samples': 16, 'num_leaves': 230, 'reg_alpha': 7, 'reg_lambda': 2.9937995575392815, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[34]\tcv_agg's valid rmse: 3.71832 + 0.00916866\n",
      "{'bagging_fraction': 0.9088260727738453, 'bagging_freq': 7, 'feature_fraction': 0.7682838434935467, 'learning_rate': 0.016230802511972717, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 7, 'reg_lambda': 2.7650949078420686, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.201717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[406]\tcv_agg's valid rmse: 3.68853 + 0.00620454\n",
      "{'bagging_fraction': 0.9177022453415298, 'bagging_freq': 7, 'feature_fraction': 0.775586846193078, 'learning_rate': 0.02964793258923834, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 7, 'reg_lambda': 2.848195902638218, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[224]\tcv_agg's valid rmse: 3.69221 + 0.0105\n",
      "{'bagging_fraction': 0.8410481944077957, 'bagging_freq': 8, 'feature_fraction': 0.7499075612116564, 'learning_rate': 0.013556362940723859, 'min_child_samples': 16, 'num_leaves': 280, 'reg_alpha': 7, 'reg_lambda': 1.8916969966980561, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[210]\tcv_agg's valid rmse: 3.69724 + 0.0114016\n",
      "{'bagging_fraction': 0.6892012119502908, 'bagging_freq': 9, 'feature_fraction': 0.5156046004363076, 'learning_rate': 0.21214389733281974, 'min_child_samples': 16, 'num_leaves': 150, 'reg_alpha': 7, 'reg_lambda': 6.18847005457185, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[7]\tcv_agg's valid rmse: 3.76042 + 0.00649016\n",
      "{'bagging_fraction': 0.6272369909079323, 'bagging_freq': 5, 'feature_fraction': 0.7449032523357751, 'learning_rate': 0.06791374441702488, 'min_child_samples': 16, 'num_leaves': 200, 'reg_alpha': 0, 'reg_lambda': 3.3416874863644837, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[35]\tcv_agg's valid rmse: 3.72662 + 0.00742824\n",
      "{'bagging_fraction': 0.7966647756833211, 'bagging_freq': 7, 'feature_fraction': 0.6184070212810147, 'learning_rate': 0.19383501258362018, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 4, 'reg_lambda': 1.2143934086155816, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[16]\tcv_agg's valid rmse: 3.73637 + 0.00439409\n",
      "{'bagging_fraction': 0.9960399841724703, 'bagging_freq': 8, 'feature_fraction': 0.801734312459067, 'learning_rate': 0.15880386075925276, 'min_child_samples': 16, 'num_leaves': 140, 'reg_alpha': 3, 'reg_lambda': 4.87837731863211, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[15]\tcv_agg's valid rmse: 3.73978 + 0.00787421\n",
      "{'bagging_fraction': 0.919983174955275, 'bagging_freq': 2, 'feature_fraction': 0.5809795191613055, 'learning_rate': 0.23887137836875277, 'min_child_samples': 16, 'num_leaves': 60, 'reg_alpha': 7, 'reg_lambda': 2.526217027086027, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73405                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "Training until validation scores don't improve for 20 rounds                     \n",
      "Early stopping, best iteration is:                                               \n",
      "[10]\tcv_agg's valid rmse: 3.74192 + 0.0165366\n",
      "100%|██████████| 30/30 [04:56<00:00,  9.87s/trial, best loss: 3.6879642084107567]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\90124126.py:21: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  prediction_train = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.247098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73388\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.390986\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[752]\ttrain's rmse: 3.63352\tvalid's rmse: 3.69068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\90124126.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(bst.predict(train[features].loc[eval_index]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.272231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73391\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396781\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[943]\ttrain's rmse: 3.62733\tvalid's rmse: 3.64788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\90124126.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(bst.predict(train[features].loc[eval_index]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.270449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73390\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.390348\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1056]\ttrain's rmse: 3.60329\tvalid's rmse: 3.70727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\90124126.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(bst.predict(train[features].loc[eval_index]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.242581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73391\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.391392\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1206]\ttrain's rmse: 3.57757\tvalid's rmse: 3.77831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\90124126.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(bst.predict(train[features].loc[eval_index]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.295397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73388\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.398675\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[646]\ttrain's rmse: 3.66798\tvalid's rmse: 3.57939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\90124126.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  prediction_train = prediction_train.append(pd.Series(bst.predict(train[features].loc[eval_index]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.690683620082564, 3.6478790166855783, 3.707267070867506, 3.7783064335534613, 3.5793879232664563] 3.6807048128911126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\90124126.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['target'] = prediction_test / 5\n"
     ]
    }
   ],
   "source": [
    "train_LGBM, test_LGBM = feature_select_wrapper(train, test)\n",
    "best_clf = param_hyperopt(train_LGBM)\n",
    "train_predict(train_LGBM, test_LGBM, best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Model: NLP feature optimization, XGBoost, Bayes_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found there were many columns related to ID, such as `merchant_id`, `merchant_category_id`, `state_id`, `subsector_id`, `city_id`, these values inflect customer's behavior. For example, for a customer A, if a certain merchant id happens a lot in his transaction record, it means A likes this merchant. Furthermore, if this merchant record in many customers', it means this merchant is popular, and it also means customer A is similar to other customers, if not, A has a special like. \n",
    "\n",
    "In order to mining this information, I will apply CountVector and TF-IDF. Specificly, CountVector can extract merchant information of a customer, and TF-IDF can extract if many customers like one product at the same time.\n",
    "\n",
    "If we apply NLP approaches, there is an issue we should consider which is there are too many new features and most of them are sparse. So I'll introduce associated method `sparse` from `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2469"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意，该数据集是最初始的数据集\n",
    "train = pd.read_csv('./dataset/train.csv')\n",
    "test =  pd.read_csv('./dataset/test.csv')\n",
    "merchant = pd.read_csv('./dataset/merchants.csv')\n",
    "new_transaction = pd.read_csv('./dataset/new_merchant_transactions.csv')\n",
    "history_transaction = pd.read_csv('./dataset/historical_transactions.csv')\n",
    "transaction = pd.concat([new_transaction, history_transaction], axis=0, ignore_index=True)\n",
    "del new_transaction\n",
    "del history_transaction\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id\n",
      "merchant_category_id\n",
      "state_id\n",
      "subsector_id\n",
      "city_id\n"
     ]
    }
   ],
   "source": [
    "nlp_features = ['merchant_id', 'merchant_category_id', 'state_id', 'subsector_id', 'city_id']\n",
    "\n",
    "for co in nlp_features:\n",
    "    print(co)\n",
    "    transaction[co] = transaction[co].astype(str)\n",
    "    temp = transaction[transaction['month_lag']>=0].groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_new']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id')\n",
    "    test = pd.merge(test, temp, how='left', on='card_id')\n",
    "\n",
    "    temp = transaction[transaction['month_lag']<0].groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_hist']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id')\n",
    "    test = pd.merge(test, temp, how='left', on='card_id')\n",
    "\n",
    "    temp = transaction.groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_all']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id').fillna(\"-1\")\n",
    "    test = pd.merge(test, temp, how='left', on='card_id').fillna(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id_hist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_category_id_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_category_id_hist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_category_id_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_id_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_id_hist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_id_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsector_id_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsector_id_hist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsector_id_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_id_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_id_hist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_id_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hydon\\AppData\\Local\\Temp\\ipykernel_8588\\4140852302.py:21: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tfv.fit(train[feature].append(test[feature]))\n",
      "c:\\Users\\hydon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 创建空DataFrame用于保存NLP特征\n",
    "train_x = pd.DataFrame()\n",
    "test_x = pd.DataFrame()\n",
    "\n",
    "# 实例化CountVectorizer评估器与TfidfVectorizer评估器\n",
    "cntv = CountVectorizer()\n",
    "tfv = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "\n",
    "# 创建空列表用户保存修正后的列名称\n",
    "vector_feature =[]\n",
    "for co in ['merchant_id', 'merchant_category_id', 'state_id', 'subsector_id', 'city_id']:\n",
    "    vector_feature.extend([co+'_new', co+'_hist', co+'_all'])\n",
    "    \n",
    "# 提取每一列进行新特征衍生\n",
    "for feature in vector_feature:\n",
    "    print(feature)\n",
    "    cntv.fit([feature] + test[feature])\n",
    "    train_x = sparse.hstack((train_x, cntv.transform(train[feature]))).tocsr()\n",
    "    test_x = sparse.hstack((test_x, cntv.transform(test[feature]))).tocsr()\n",
    "    \n",
    "    tfv.fit(train[feature].append(test[feature]))\n",
    "    train_x = sparse.hstack((train_x, tfv.transform(train[feature]))).tocsr()\n",
    "    test_x = sparse.hstack((test_x, tfv.transform(test[feature]))).tocsr()\n",
    "    \n",
    "# 保存NLP特征衍生结果\n",
    "sparse.save_npz(\"./dataset/preprocess/train_nlp.npz\", train_x)\n",
    "sparse.save_npz(\"./dataset/preprocess/test_nlp.npz\", test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 4231688)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
